{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BBB (Blood-Brain Barrier), Martins et al.\n",
    "\n",
    "### Dataset Description: As a membrane separating circulating blood and brain extracellular fluid, the blood-brain barrier (BBB) is the protection layer that blocks most foreign drugs. Thus the ability of a drug to penetrate the barrier to deliver to the site of action forms a crucial challenge in development of drugs for central nervous system From MoleculeNet.\n",
    "\n",
    "### Task Description: Binary classification. Given a drug SMILES string, predict the activity of BBB.\n",
    "\n",
    "### Dataset Statistics: 1,975 drugs.\n",
    "\n",
    "### Metric: AUROC\n",
    "\n",
    "## Leaderboard\n",
    "\n",
    "| Rank | Model                            | Contact           | Link          | #Params   | AUROC         |\n",
    "|------|----------------------------------|-------------------|---------------|-----------|---------------|\n",
    "| 1    | MapLight                         | Jim Notwell       | GitHub, Paper | N/A       | 0.916 ± 0.001 |\n",
    "| 2    | Lantern RADR Ensemble            | Rick Fontenot     | GitHub, Paper | N/A       | 0.915 ± 0.002 |\n",
    "| 3    | MapLight + GNN                   | Jim Notwell       | GitHub, Paper | N/A       | 0.913 ± 0.001 |\n",
    "| 4    | Lantern RADR Deep Neural Network | Rick Fontenot     | GitHub, Paper | N/A       | 0.912 ± 0.003 |\n",
    "| 5    | ZairaChem                        | Gemma Turon       | GitHub, Paper | N/A       | 0.910 ± 0.024 |\n",
    "| 6    | Lantern RADR Random Forest       | Rick Fontenot     | GitHub, Paper | 319       | 0.908 ± 0.002 |\n",
    "| 7    | Lantern RADR SVM                 | Rick Fontenot     | GitHub, Paper | 241       | 0.905 ± 0.007 |\n",
    "| 8    | Lantern RADR Logistic Regression | Rick Fontenot     | GitHub, Paper | 456       | 0.903 ± 0.002 |\n",
    "| 9    | SimGCN                           | Suman Kalyan Bera | GitHub, Paper | 1,103,000 | 0.901 ± 0.007 |\n",
    "| 10   | ContextPred                      | Kexin Huang       | GitHub, Paper | 2,067,053 | 0.897 ± 0.004 |\n",
    "| 11   | AttrMasking                      | Kexin Huang       | GitHub, Paper | 2,067,053 | 0.892 ± 0.012 |\n",
    "| 12   | RDKit2D + MLP (DeepPurpose)      | Kexin Huang       | GitHub, Paper | 633,409   | 0.889 ± 0.016 |\n",
    "| 13   | Chemprop-RDKit                   | Kyle Swanson      | GitHub, Paper | N/A       | 0.869 ± 0.027 |\n",
    "| 14   | AttentiveFP                      | Kexin Huang       | GitHub, Paper | 300,806   | 0.855 ± 0.011 |\n",
    "| 15   | GCN                              | Kexin Huang       | GitHub, Paper | 191,810   | 0.842 ± 0.016 |\n",
    "| 16   | NeuralFP                         | Kexin Huang       | GitHub, Paper | 480,193   | 0.836 ± 0.009 |\n",
    "| 17   | Morgan + MLP (DeepPurpose)       | Kexin Huang       | GitHub, Paper | 1,477,185 | 0.823 ± 0.015 |\n",
    "| 18   | Chemprop                         | Kyle Swanson      | GitHub, Paper | N/A       | 0.821 ± 0.112 |\n",
    "| 19   | Basic ML                         | Nilavo Boral      | GitHub, Paper | N/A       | 0.811 ± 0.013 |\n",
    "| 20   | CNN (DeepPurpose)                | Kexin Huang       | GitHub, Paper | 226,625   | 0.781 ± 0.030 |\n",
    "| 21   | Euclia ML model                  | Euclia            | GitHub, Paper | 50        | 0.725 ± 0.019 |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86a59e63e6143206"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 14:34:45.668548: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 14:34:45.700890: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 14:34:45.701732: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 14:34:46.275364: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deepmol.pipeline import Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T14:34:49.076124454Z",
     "start_time": "2023-11-21T14:34:45.245187041Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    trial_id   mean    std\n0          2  0.500  0.000\n1          5  0.500  0.000\n2          8  0.722  0.011\n3         10  0.724  0.009\n4         11  0.716  0.009\n5         12  0.715  0.009\n6         17  0.708  0.017\n7         18  0.760  0.012\n8         22  0.704  0.014\n9         23  0.744  0.007\n10        24  0.570  0.019\n11        28  0.658  0.021\n12        31  0.453  0.006\n13        33  0.735  0.022\n14        34  0.663  0.013\n15        36  0.390  0.003\n16        41  0.749  0.008\n17        42  0.500  0.000\n18        45  0.742  0.014\n19        46  0.719  0.012\n20        47  0.751  0.002\n21        50  0.770  0.012\n22        51  0.770  0.012\n23        52  0.770  0.009\n24        54  0.736  0.035\n25        55  0.774  0.007\n26        56  0.774  0.007\n27        57  0.774  0.007\n28        58  0.774  0.007\n29        60  0.746  0.007\n30        61  0.774  0.007\n31        62  0.774  0.007\n32        63  0.749  0.021\n33        65  0.762  0.005\n34        66  0.658  0.002\n35        69  0.731  0.033\n36        70  0.736  0.016\n37        72  0.723  0.018\n38        73  0.772  0.024\n39        74  0.718  0.021\n40        77  0.500  0.000\n41        78  0.718  0.018\n42        79  0.732  0.039\n43        80  0.723  0.011\n44        87  0.750  0.028\n45        88  0.758  0.024\n46        90  0.726  0.025\n47        91  0.782  0.017\n48        92  0.786  0.031\n49        95  0.762  0.020\n50        96  0.753  0.007\n51        97  0.759  0.024",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_id</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>0.722</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>0.724</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0.716</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12</td>\n      <td>0.715</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17</td>\n      <td>0.708</td>\n      <td>0.017</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>18</td>\n      <td>0.760</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>22</td>\n      <td>0.704</td>\n      <td>0.014</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>23</td>\n      <td>0.744</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>24</td>\n      <td>0.570</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>28</td>\n      <td>0.658</td>\n      <td>0.021</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>31</td>\n      <td>0.453</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>33</td>\n      <td>0.735</td>\n      <td>0.022</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>34</td>\n      <td>0.663</td>\n      <td>0.013</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>36</td>\n      <td>0.390</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>41</td>\n      <td>0.749</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>42</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>45</td>\n      <td>0.742</td>\n      <td>0.014</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>46</td>\n      <td>0.719</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>47</td>\n      <td>0.751</td>\n      <td>0.002</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>50</td>\n      <td>0.770</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>51</td>\n      <td>0.770</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>52</td>\n      <td>0.770</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>54</td>\n      <td>0.736</td>\n      <td>0.035</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>55</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>56</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>57</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>58</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>60</td>\n      <td>0.746</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>61</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>62</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>63</td>\n      <td>0.749</td>\n      <td>0.021</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>65</td>\n      <td>0.762</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>66</td>\n      <td>0.658</td>\n      <td>0.002</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>69</td>\n      <td>0.731</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>70</td>\n      <td>0.736</td>\n      <td>0.016</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>72</td>\n      <td>0.723</td>\n      <td>0.018</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>73</td>\n      <td>0.772</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>74</td>\n      <td>0.718</td>\n      <td>0.021</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>77</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>78</td>\n      <td>0.718</td>\n      <td>0.018</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>79</td>\n      <td>0.732</td>\n      <td>0.039</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>80</td>\n      <td>0.723</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>87</td>\n      <td>0.750</td>\n      <td>0.028</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>88</td>\n      <td>0.758</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>90</td>\n      <td>0.726</td>\n      <td>0.025</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>91</td>\n      <td>0.782</td>\n      <td>0.017</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>92</td>\n      <td>0.786</td>\n      <td>0.031</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>95</td>\n      <td>0.762</td>\n      <td>0.020</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>96</td>\n      <td>0.753</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>97</td>\n      <td>0.759</td>\n      <td>0.024</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read results\n",
    "results = pd.read_csv('bbb/tdc_test_set_results.txt', sep=',', header=None, dtype={0: int, 1: float, 2: float})\n",
    "# set columns\n",
    "results.columns = ['trial_id', 'mean', 'std']\n",
    "results\n",
    "# order res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T14:34:49.090509440Z",
     "start_time": "2023-11-21T14:34:49.074929370Z"
    }
   },
   "id": "6753179565f6d258"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "    trial_id   mean    std\n48        92  0.786  0.031\n47        91  0.782  0.017\n25        55  0.774  0.007\n26        56  0.774  0.007\n27        57  0.774  0.007\n28        58  0.774  0.007\n30        61  0.774  0.007\n31        62  0.774  0.007\n38        73  0.772  0.024\n21        50  0.770  0.012\n22        51  0.770  0.012\n23        52  0.770  0.009\n49        95  0.762  0.020\n33        65  0.762  0.005\n7         18  0.760  0.012\n51        97  0.759  0.024\n45        88  0.758  0.024\n50        96  0.753  0.007\n20        47  0.751  0.002\n44        87  0.750  0.028\n32        63  0.749  0.021\n16        41  0.749  0.008\n29        60  0.746  0.007\n9         23  0.744  0.007\n18        45  0.742  0.014\n24        54  0.736  0.035\n36        70  0.736  0.016\n13        33  0.735  0.022\n42        79  0.732  0.039\n35        69  0.731  0.033\n46        90  0.726  0.025\n3         10  0.724  0.009\n37        72  0.723  0.018\n43        80  0.723  0.011\n2          8  0.722  0.011\n19        46  0.719  0.012\n39        74  0.718  0.021\n41        78  0.718  0.018\n4         11  0.716  0.009\n5         12  0.715  0.009\n6         17  0.708  0.017\n8         22  0.704  0.014\n14        34  0.663  0.013\n11        28  0.658  0.021\n34        66  0.658  0.002\n10        24  0.570  0.019\n0          2  0.500  0.000\n1          5  0.500  0.000\n17        42  0.500  0.000\n40        77  0.500  0.000\n12        31  0.453  0.006\n15        36  0.390  0.003",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_id</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>48</th>\n      <td>92</td>\n      <td>0.786</td>\n      <td>0.031</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>91</td>\n      <td>0.782</td>\n      <td>0.017</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>55</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>56</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>57</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>58</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>61</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>62</td>\n      <td>0.774</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>73</td>\n      <td>0.772</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>50</td>\n      <td>0.770</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>51</td>\n      <td>0.770</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>52</td>\n      <td>0.770</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>95</td>\n      <td>0.762</td>\n      <td>0.020</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>65</td>\n      <td>0.762</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>18</td>\n      <td>0.760</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>97</td>\n      <td>0.759</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>88</td>\n      <td>0.758</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>96</td>\n      <td>0.753</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>47</td>\n      <td>0.751</td>\n      <td>0.002</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>87</td>\n      <td>0.750</td>\n      <td>0.028</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>63</td>\n      <td>0.749</td>\n      <td>0.021</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>41</td>\n      <td>0.749</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>60</td>\n      <td>0.746</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>23</td>\n      <td>0.744</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>45</td>\n      <td>0.742</td>\n      <td>0.014</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>54</td>\n      <td>0.736</td>\n      <td>0.035</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>70</td>\n      <td>0.736</td>\n      <td>0.016</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>33</td>\n      <td>0.735</td>\n      <td>0.022</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>79</td>\n      <td>0.732</td>\n      <td>0.039</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>69</td>\n      <td>0.731</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>90</td>\n      <td>0.726</td>\n      <td>0.025</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>0.724</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>72</td>\n      <td>0.723</td>\n      <td>0.018</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>80</td>\n      <td>0.723</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>0.722</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>46</td>\n      <td>0.719</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>74</td>\n      <td>0.718</td>\n      <td>0.021</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>78</td>\n      <td>0.718</td>\n      <td>0.018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0.716</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12</td>\n      <td>0.715</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17</td>\n      <td>0.708</td>\n      <td>0.017</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>22</td>\n      <td>0.704</td>\n      <td>0.014</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>34</td>\n      <td>0.663</td>\n      <td>0.013</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>28</td>\n      <td>0.658</td>\n      <td>0.021</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>66</td>\n      <td>0.658</td>\n      <td>0.002</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>24</td>\n      <td>0.570</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>42</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>77</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>31</td>\n      <td>0.453</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>36</td>\n      <td>0.390</td>\n      <td>0.003</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order results by mean (std in case of tie)\n",
    "results = results.sort_values(by=['mean', 'std'], ascending=False)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T14:34:49.108405677Z",
     "start_time": "2023-11-21T14:34:49.091462724Z"
    }
   },
   "id": "c418a24aeebde864"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:04:06] Initializing Normalizer\n",
      "2023-11-11 21:04:06.125985: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-11-11 21:04:06.126034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: JOAOPC\n",
      "2023-11-11 21:04:06.126094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: JOAOPC\n",
      "2023-11-11 21:04:06.126213: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.147.5\n",
      "2023-11-11 21:04:06.126235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.147.5\n",
      "2023-11-11 21:04:06.126240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.147.5\n"
     ]
    }
   ],
   "source": [
    "# load best trial pipeline (rank #20)\n",
    "best_trial_id = int(results.iloc[0]['trial_id'])\n",
    "pipeline = Pipeline.load(f\"bbb/trial_{best_trial_id}/\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T21:04:06.483836045Z",
     "start_time": "2023-11-11T21:04:05.991307378Z"
    }
   },
   "id": "90e40046d6b150ce"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[('label_encoder',\n  <deepmol.base.transformer.PassThroughTransformer at 0x7f97dd83e740>),\n ('standardizer',\n  <deepmol.standardizer.custom_standardizer.CustomStandardizer at 0x7f97dd83e440>),\n ('featurizer',\n  <deepmol.compound_featurization.rdkit_fingerprints.RDKFingerprint at 0x7f97dd83e860>),\n ('scaler',\n  <deepmol.base.transformer.PassThroughTransformer at 0x7f97dda3d3f0>),\n ('model',\n  KerasModel(model_builder=<function keras_1d_cnn_model_builder at 0x7f970fc90d30>,\n             model_dir='/tmp/tmp1rk748t7'))]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T21:04:41.496928194Z",
     "start_time": "2023-11-11T21:04:41.450101162Z"
    }
   },
   "id": "aca45806698765d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "74ca8a552f18c430"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
