{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BBB (Blood-Brain Barrier), Martins et al.\n",
    "\n",
    "### Dataset Description: As a membrane separating circulating blood and brain extracellular fluid, the blood-brain barrier (BBB) is the protection layer that blocks most foreign drugs. Thus the ability of a drug to penetrate the barrier to deliver to the site of action forms a crucial challenge in development of drugs for central nervous system From MoleculeNet.\n",
    "\n",
    "### Task Description: Binary classification. Given a drug SMILES string, predict the activity of BBB.\n",
    "\n",
    "### Dataset Statistics: 1,975 drugs.\n",
    "\n",
    "### Metric: AUROC\n",
    "\n",
    "## Leaderboard\n",
    "\n",
    "| Rank | Model                            | Contact           | Link          | #Params   | AUROC         |\n",
    "|------|----------------------------------|-------------------|---------------|-----------|---------------|\n",
    "| 1    | MapLight                         | Jim Notwell       | GitHub, Paper | N/A       | 0.916 ± 0.001 |\n",
    "| 2    | Lantern RADR Ensemble            | Rick Fontenot     | GitHub, Paper | N/A       | 0.915 ± 0.002 |\n",
    "| 3    | MapLight + GNN                   | Jim Notwell       | GitHub, Paper | N/A       | 0.913 ± 0.001 |\n",
    "| 4    | Lantern RADR Deep Neural Network | Rick Fontenot     | GitHub, Paper | N/A       | 0.912 ± 0.003 |\n",
    "| 5    | ZairaChem                        | Gemma Turon       | GitHub, Paper | N/A       | 0.910 ± 0.024 |\n",
    "| 6    | Lantern RADR Random Forest       | Rick Fontenot     | GitHub, Paper | 319       | 0.908 ± 0.002 |\n",
    "| 7    | Lantern RADR SVM                 | Rick Fontenot     | GitHub, Paper | 241       | 0.905 ± 0.007 |\n",
    "| 8    | Lantern RADR Logistic Regression | Rick Fontenot     | GitHub, Paper | 456       | 0.903 ± 0.002 |\n",
    "| 9    | SimGCN                           | Suman Kalyan Bera | GitHub, Paper | 1,103,000 | 0.901 ± 0.007 |\n",
    "| 10   | ContextPred                      | Kexin Huang       | GitHub, Paper | 2,067,053 | 0.897 ± 0.004 |\n",
    "| 11   | AttrMasking                      | Kexin Huang       | GitHub, Paper | 2,067,053 | 0.892 ± 0.012 |\n",
    "| 12   | RDKit2D + MLP (DeepPurpose)      | Kexin Huang       | GitHub, Paper | 633,409   | 0.889 ± 0.016 |\n",
    "| 13   | Chemprop-RDKit                   | Kyle Swanson      | GitHub, Paper | N/A       | 0.869 ± 0.027 |\n",
    "| 14   | AttentiveFP                      | Kexin Huang       | GitHub, Paper | 300,806   | 0.855 ± 0.011 |\n",
    "| 15   | GCN                              | Kexin Huang       | GitHub, Paper | 191,810   | 0.842 ± 0.016 |\n",
    "| 16   | NeuralFP                         | Kexin Huang       | GitHub, Paper | 480,193   | 0.836 ± 0.009 |\n",
    "| 17   | Morgan + MLP (DeepPurpose)       | Kexin Huang       | GitHub, Paper | 1,477,185 | 0.823 ± 0.015 |\n",
    "| 18   | Chemprop                         | Kyle Swanson      | GitHub, Paper | N/A       | 0.821 ± 0.112 |\n",
    "| 19   | Basic ML                         | Nilavo Boral      | GitHub, Paper | N/A       | 0.811 ± 0.013 |\n",
    "| 20   | CNN (DeepPurpose)                | Kexin Huang       | GitHub, Paper | 226,625   | 0.781 ± 0.030 |\n",
    "| 21   | Euclia ML model                  | Euclia            | GitHub, Paper | 50        | 0.725 ± 0.019 |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86a59e63e6143206"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:17:33.836208: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-08 14:17:34.014050: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-08 14:17:34.015154: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-08 14:17:34.945914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deepmol.pipeline import Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:17:38.605527098Z",
     "start_time": "2023-11-08T14:17:33.238037883Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "    trial_id   mean    std\n0          2  0.500  0.000\n1          5  0.500  0.000\n2          6  0.500  0.000\n3          8  0.722  0.006\n4         10  0.720  0.006\n5         11  0.721  0.009\n6         12  0.715  0.010\n7         13  0.747  0.011\n8         14  0.730  0.019\n9         15  0.695  0.017\n10        17  0.748  0.009\n11        18  0.500  0.000\n12        22  0.688  0.033\n13        24  0.731  0.024\n14        26  0.738  0.025\n15        32  0.743  0.007\n16        33  0.758  0.007\n17        41  0.697  0.033\n18        43  0.745  0.013\n19        46  0.694  0.009\n20        48  0.757  0.003\n21        50  0.737  0.013\n22        51  0.546  0.008\n23        52  0.737  0.012\n24        53  0.738  0.012\n25        54  0.626  0.010\n26        57  0.393  0.005\n27        62  0.727  0.014\n28        65  0.729  0.024\n29        66  0.538  0.003\n30        67  0.500  0.000\n31        69  0.721  0.015\n32        70  0.707  0.027\n33        71  0.755  0.014\n34        72  0.754  0.026\n35        73  0.723  0.012\n36        74  0.722  0.011\n37        75  0.720  0.012\n38        76  0.717  0.019\n39        79  0.719  0.008\n40        81  0.722  0.012\n41        82  0.718  0.011\n42        85  0.724  0.022\n43        87  0.722  0.012\n44        88  0.776  0.021\n45        89  0.335  0.002\n46        91  0.724  0.010\n47        92  0.719  0.016\n48        93  0.741  0.004\n49        96  0.500  0.000\n50        97  0.745  0.019\n51        99  0.636  0.009",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_id</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>0.722</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>0.720</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>11</td>\n      <td>0.721</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>12</td>\n      <td>0.715</td>\n      <td>0.010</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>13</td>\n      <td>0.747</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14</td>\n      <td>0.730</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>0.695</td>\n      <td>0.017</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>17</td>\n      <td>0.748</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>18</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>22</td>\n      <td>0.688</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>24</td>\n      <td>0.731</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>26</td>\n      <td>0.738</td>\n      <td>0.025</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>32</td>\n      <td>0.743</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>33</td>\n      <td>0.758</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>41</td>\n      <td>0.697</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>43</td>\n      <td>0.745</td>\n      <td>0.013</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>46</td>\n      <td>0.694</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>48</td>\n      <td>0.757</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>50</td>\n      <td>0.737</td>\n      <td>0.013</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>51</td>\n      <td>0.546</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>52</td>\n      <td>0.737</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>53</td>\n      <td>0.738</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>54</td>\n      <td>0.626</td>\n      <td>0.010</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>57</td>\n      <td>0.393</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>62</td>\n      <td>0.727</td>\n      <td>0.014</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>65</td>\n      <td>0.729</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>66</td>\n      <td>0.538</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>67</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>69</td>\n      <td>0.721</td>\n      <td>0.015</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>70</td>\n      <td>0.707</td>\n      <td>0.027</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>71</td>\n      <td>0.755</td>\n      <td>0.014</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>72</td>\n      <td>0.754</td>\n      <td>0.026</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>73</td>\n      <td>0.723</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>74</td>\n      <td>0.722</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>75</td>\n      <td>0.720</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>76</td>\n      <td>0.717</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>79</td>\n      <td>0.719</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>81</td>\n      <td>0.722</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>82</td>\n      <td>0.718</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>85</td>\n      <td>0.724</td>\n      <td>0.022</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>87</td>\n      <td>0.722</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>88</td>\n      <td>0.776</td>\n      <td>0.021</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>89</td>\n      <td>0.335</td>\n      <td>0.002</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>91</td>\n      <td>0.724</td>\n      <td>0.010</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>92</td>\n      <td>0.719</td>\n      <td>0.016</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>93</td>\n      <td>0.741</td>\n      <td>0.004</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>96</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>97</td>\n      <td>0.745</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>99</td>\n      <td>0.636</td>\n      <td>0.009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read results\n",
    "results = pd.read_csv('bbb/tdc_test_set_results.txt', sep=',', header=None, dtype={0: int, 1: float, 2: float})\n",
    "# set columns\n",
    "results.columns = ['trial_id', 'mean', 'std']\n",
    "results\n",
    "# order res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:15:52.556021368Z",
     "start_time": "2023-11-08T14:15:52.514388340Z"
    }
   },
   "id": "6753179565f6d258"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "    trial_id   mean    std\n44        88  0.776  0.021\n16        33  0.758  0.007\n20        48  0.757  0.003\n33        71  0.755  0.014\n34        72  0.754  0.026\n10        17  0.748  0.009\n7         13  0.747  0.011\n50        97  0.745  0.019\n18        43  0.745  0.013\n15        32  0.743  0.007\n48        93  0.741  0.004\n14        26  0.738  0.025\n24        53  0.738  0.012\n21        50  0.737  0.013\n23        52  0.737  0.012\n13        24  0.731  0.024\n8         14  0.730  0.019\n28        65  0.729  0.024\n27        62  0.727  0.014\n42        85  0.724  0.022\n46        91  0.724  0.010\n35        73  0.723  0.012\n40        81  0.722  0.012\n43        87  0.722  0.012\n36        74  0.722  0.011\n3          8  0.722  0.006\n31        69  0.721  0.015\n5         11  0.721  0.009\n37        75  0.720  0.012\n4         10  0.720  0.006\n47        92  0.719  0.016\n39        79  0.719  0.008\n41        82  0.718  0.011\n38        76  0.717  0.019\n6         12  0.715  0.010\n32        70  0.707  0.027\n17        41  0.697  0.033\n9         15  0.695  0.017\n19        46  0.694  0.009\n12        22  0.688  0.033\n51        99  0.636  0.009\n25        54  0.626  0.010\n22        51  0.546  0.008\n29        66  0.538  0.003\n0          2  0.500  0.000\n1          5  0.500  0.000\n2          6  0.500  0.000\n11        18  0.500  0.000\n30        67  0.500  0.000\n49        96  0.500  0.000\n26        57  0.393  0.005\n45        89  0.335  0.002",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trial_id</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44</th>\n      <td>88</td>\n      <td>0.776</td>\n      <td>0.021</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>33</td>\n      <td>0.758</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>48</td>\n      <td>0.757</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>71</td>\n      <td>0.755</td>\n      <td>0.014</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>72</td>\n      <td>0.754</td>\n      <td>0.026</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>17</td>\n      <td>0.748</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>13</td>\n      <td>0.747</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>97</td>\n      <td>0.745</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>43</td>\n      <td>0.745</td>\n      <td>0.013</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>32</td>\n      <td>0.743</td>\n      <td>0.007</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>93</td>\n      <td>0.741</td>\n      <td>0.004</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>26</td>\n      <td>0.738</td>\n      <td>0.025</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>53</td>\n      <td>0.738</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>50</td>\n      <td>0.737</td>\n      <td>0.013</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>52</td>\n      <td>0.737</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>24</td>\n      <td>0.731</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14</td>\n      <td>0.730</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>65</td>\n      <td>0.729</td>\n      <td>0.024</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>62</td>\n      <td>0.727</td>\n      <td>0.014</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>85</td>\n      <td>0.724</td>\n      <td>0.022</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>91</td>\n      <td>0.724</td>\n      <td>0.010</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>73</td>\n      <td>0.723</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>81</td>\n      <td>0.722</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>87</td>\n      <td>0.722</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>74</td>\n      <td>0.722</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>0.722</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>69</td>\n      <td>0.721</td>\n      <td>0.015</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>11</td>\n      <td>0.721</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>75</td>\n      <td>0.720</td>\n      <td>0.012</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>0.720</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>92</td>\n      <td>0.719</td>\n      <td>0.016</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>79</td>\n      <td>0.719</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>82</td>\n      <td>0.718</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>76</td>\n      <td>0.717</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>12</td>\n      <td>0.715</td>\n      <td>0.010</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>70</td>\n      <td>0.707</td>\n      <td>0.027</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>41</td>\n      <td>0.697</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>0.695</td>\n      <td>0.017</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>46</td>\n      <td>0.694</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>22</td>\n      <td>0.688</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>99</td>\n      <td>0.636</td>\n      <td>0.009</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>54</td>\n      <td>0.626</td>\n      <td>0.010</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>51</td>\n      <td>0.546</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>66</td>\n      <td>0.538</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>18</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>67</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>96</td>\n      <td>0.500</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>57</td>\n      <td>0.393</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>89</td>\n      <td>0.335</td>\n      <td>0.002</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order results by mean (std in case of tie)\n",
    "results = results.sort_values(by=['mean', 'std'], ascending=False)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:15:55.792304181Z",
     "start_time": "2023-11-08T14:15:55.788804018Z"
    }
   },
   "id": "c418a24aeebde864"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:18:31] Initializing Normalizer\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/tmpw20t292e/model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# load best trial pipeline\u001B[39;00m\n\u001B[1;32m      2\u001B[0m best_trial_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(results\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrial_id\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m----> 3\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m \u001B[43mPipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbbb/trial_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mbest_trial_id\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/deepmol_case_studies/lib/python3.10/site-packages/deepmol/pipeline/pipeline.py:340\u001B[0m, in \u001B[0;36mPipeline.load\u001B[0;34m(cls, path)\u001B[0m\n\u001B[1;32m    338\u001B[0m     steps\u001B[38;5;241m.\u001B[39mappend((step_name, transformer))\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m step[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredictor\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 340\u001B[0m     predictor \u001B[38;5;241m=\u001B[39m \u001B[43m_get_predictor_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_type\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    341\u001B[0m     predictor\u001B[38;5;241m.\u001B[39m_is_fitted \u001B[38;5;241m=\u001B[39m step_is_fitted\n\u001B[1;32m    342\u001B[0m     steps\u001B[38;5;241m.\u001B[39mappend((step_name, predictor))\n",
      "File \u001B[0;32m~/anaconda3/envs/deepmol_case_studies/lib/python3.10/site-packages/deepmol/models/sklearn_models.py:192\u001B[0m, in \u001B[0;36mSklearnModel.load\u001B[0;34m(cls, folder_path, **kwargs)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;124;03mLoads scikit-learn model from joblib or pickle file on disk.\u001B[39;00m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;124;03mSupported extensions: .joblib, .pkl\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;124;03m    The loaded scikit-learn model.\u001B[39;00m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    191\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_filename(folder_path)\n\u001B[0;32m--> 192\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_from_disk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;66;03m# change file path to keep the extension but add _params\u001B[39;00m\n\u001B[1;32m    194\u001B[0m parameters_file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(model_path\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_params.\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m model_path\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/deepmol_case_studies/lib/python3.10/site-packages/deepmol/models/_utils.py:60\u001B[0m, in \u001B[0;36mload_from_disk\u001B[0;34m(filename)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extension \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 60\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_pickle_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mAttributeError\u001B[39;00m):\n\u001B[1;32m     62\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(filename, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "File \u001B[0;32m~/anaconda3/envs/deepmol_case_studies/lib/python3.10/site-packages/deepmol/utils/utils.py:115\u001B[0m, in \u001B[0;36mload_pickle_file\u001B[0;34m(input_file)\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mload(cast(IO[\u001B[38;5;28mbytes\u001B[39m], unzipped_file))\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minput_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mload(opened_file)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/tmp/tmpw20t292e/model.pkl'"
     ]
    }
   ],
   "source": [
    "# load best trial pipeline (rank #21)\n",
    "best_trial_id = int(results.iloc[0]['trial_id'])\n",
    "pipeline = Pipeline.load(f\"bbb/trial_{best_trial_id}/\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T14:18:31.822900669Z",
     "start_time": "2023-11-08T14:18:31.171934675Z"
    }
   },
   "id": "90e40046d6b150ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aca45806698765d8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
