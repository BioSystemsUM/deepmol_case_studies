{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a59e63e6143206",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Caco-2 (Cell Effective Permeability), Wang et al.\n",
    "\n",
    "### Dataset Description: The human colon epithelial cancer cell line, Caco-2, is used as an in vitro model to simulate the human intestinal tissue. The experimental result on the rate of drug passing through the Caco-2 cells can approximate the rate at which the drug permeates through the human intestinal tissue.\n",
    "\n",
    "### Task Description: Regression. Given a drug SMILES string, predict the Caco-2 cell effective permeability.\n",
    "\n",
    "### Dataset Statistics: 906 drugs.\n",
    "\n",
    "### Metric: MAE\n",
    "\n",
    "## Leaderboard\n",
    "\n",
    "| Rank | Model                       | Contact        | Link          | #Params   | MAE           |\n",
    "|------|-----------------------------|----------------|---------------|-----------|---------------|\n",
    "| 1    | MapLight                    | Jim Notwell    | GitHub, Paper | N/A       | 0.276 ± 0.005 |\n",
    "| 2    | BaseBoosting                | Andrew Li      | GitHub, Paper | 365,713   | 0.285 ± 0.005 |\n",
    "| 3    | MolMapNet-D                 | Shen Wan Xiang | GitHub, Paper | 407,617   | 0.287 ± 0.005 |\n",
    "| 4    | MapLight + GNN              | Jim Notwell    | GitHub, Paper | N/A       | 0.287 ± 0.005 |\n",
    "| 5    | XGBoost                     | Andrew Li      | GitHub, Paper | 12        | 0.289 ± 0.011 |\n",
    "| 6    | Basic ML                    | Nilavo Boral   | GitHub, Paper | N/A       | 0.321 ± 0.005 |\n",
    "| 7    | Chemprop-RDKit              | Kyle Swanson   | GitHub, Paper | N/A       | 0.330 ± 0.024 |\n",
    "| 8    | Euclia ML model             | Euclia         | GitHub, Paper | 50        | 0.341 ± 0.004 |\n",
    "| 9    | Chemprop                    | Kyle Swanson   | GitHub, Paper | N/A       | 0.344 ± 0.015 |\n",
    "| 10   | RDKit2D + MLP (DeepPurpose) | Kexin Huang    | GitHub, Paper | 633,409   | 0.393 ± 0.024 |\n",
    "| 11   | AttentiveFP                 | Kexin Huang    | GitHub, Paper | 300,806   | 0.401 ± 0.032 |\n",
    "| 12   | CNN (DeepPurpose)           | Kexin Huang    | GitHub, Paper | 226,625   | 0.446 ± 0.036 |\n",
    "| 13   | ContextPred                 | Kexin Huang    | GitHub, Paper | 2,067,053 | 0.502 ± 0.036 |\n",
    "| 14   | NeuralFP                    | Kexin Huang    | GitHub, Paper | 480,193   | 0.530 ± 0.102 |\n",
    "| 15   | AttrMasking                 | Kexin Huang    | GitHub, Paper | 2,067,053 | 0.546 ± 0.052 |\n",
    "| 16   | GCN                         | Kexin Huang    | GitHub, Paper | 191,810   | 0.599 ± 0.104 |\n",
    "| 17   | Morgan + MLP (DeepPurpose)  | Kexin Huang    | GitHub, Paper | 1,477,185 | 0.908 ± 0.060 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:36:13.857119948Z",
     "start_time": "2023-11-21T14:36:10.244166654Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_dir_is_temp': True,\n",
       " 'model_dir': '/tmp/tmpmdw6xezf',\n",
       " 'model': AttentiveFP(\n",
       "   (model): AttentiveFPPredictor(\n",
       "     (gnn): AttentiveFPGNN(\n",
       "       (init_context): GetContext(\n",
       "         (project_node): Sequential(\n",
       "           (0): Linear(in_features=33, out_features=100, bias=True)\n",
       "           (1): LeakyReLU(negative_slope=0.01)\n",
       "         )\n",
       "         (project_edge1): Sequential(\n",
       "           (0): Linear(in_features=44, out_features=100, bias=True)\n",
       "           (1): LeakyReLU(negative_slope=0.01)\n",
       "         )\n",
       "         (project_edge2): Sequential(\n",
       "           (0): Dropout(p=0.0, inplace=False)\n",
       "           (1): Linear(in_features=200, out_features=1, bias=True)\n",
       "           (2): LeakyReLU(negative_slope=0.01)\n",
       "         )\n",
       "         (attentive_gru): AttentiveGRU1(\n",
       "           (edge_transform): Sequential(\n",
       "             (0): Dropout(p=0.0, inplace=False)\n",
       "             (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "           )\n",
       "           (gru): GRUCell(100, 100)\n",
       "         )\n",
       "       )\n",
       "       (gnn_layers): ModuleList()\n",
       "     )\n",
       "     (readout): AttentiveFPReadout(\n",
       "       (readouts): ModuleList(\n",
       "         (0-1): 2 x GlobalPool(\n",
       "           (compute_logits): Sequential(\n",
       "             (0): Linear(in_features=200, out_features=1, bias=True)\n",
       "             (1): LeakyReLU(negative_slope=0.01)\n",
       "           )\n",
       "           (project_nodes): Sequential(\n",
       "             (0): Dropout(p=0.0, inplace=False)\n",
       "             (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "           )\n",
       "           (gru): GRUCell(100, 100)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (predict): Sequential(\n",
       "       (0): Dropout(p=0.0, inplace=False)\n",
       "       (1): Linear(in_features=100, out_features=1, bias=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'model_class': deepchem.models.torch_models.attentivefp.AttentiveFP,\n",
       " 'loss': <deepchem.models.losses.L2Loss at 0x7f2ee2282890>,\n",
       " 'learning_rate': 0.001,\n",
       " 'output_types': ['prediction'],\n",
       " '_loss_fn': <deepchem.models.torch_models.torch_model._StandardLoss at 0x7f2ee2283790>,\n",
       " 'batch_size': 16,\n",
       " 'optimizer': <deepchem.models.optimizers.Adam at 0x7f2ee22839d0>,\n",
       " 'tensorboard': False,\n",
       " 'regularization_loss': None,\n",
       " 'device': 'cpu',\n",
       " 'wandb': False,\n",
       " 'wandb_logger': None,\n",
       " 'log_frequency': 100,\n",
       " '_prediction_outputs': [0],\n",
       " '_loss_outputs': [0],\n",
       " '_variance_outputs': [],\n",
       " '_other_outputs': [],\n",
       " '_built': True,\n",
       " '_output_functions': {},\n",
       " '_optimizer_for_vars': {},\n",
       " '_self_loop': True,\n",
       " '_global_step': 4200,\n",
       " '_pytorch_optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " '_lr_schedule': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deepmol.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline.load('caco/trial_54')\n",
    "pipeline.steps[-1][1].model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940939b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardizer',\n",
       "  <deepmol.base.transformer.PassThroughTransformer at 0x7f528362d4b0>),\n",
       " ('featurizer',\n",
       "  <deepmol.compound_featurization.deepchem_featurizers.MolGraphConvFeat at 0x7f528362d990>),\n",
       " ('model', <deepmol.models.deepchem_models.DeepChemModel at 0x7f2ee24f2230>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6753179565f6d258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:36:13.873529296Z",
     "start_time": "2023-11-21T14:36:13.857025107Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_id</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.365</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>1.085</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>5.328</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28</td>\n",
       "      <td>3.181</td>\n",
       "      <td>2.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34</td>\n",
       "      <td>4.826</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38</td>\n",
       "      <td>1.074</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>42</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>44</td>\n",
       "      <td>1.257</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>45</td>\n",
       "      <td>2.718</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>52</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>54</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>55</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>56</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>61</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>62</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>65</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>66</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>70</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>71</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>72</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>73</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>75</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>77</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>80</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>81</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>82</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>83</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>90</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial_id   mean    std\n",
       "0          0  0.458  0.004\n",
       "1          1  0.572  0.031\n",
       "2          2  0.618  0.062\n",
       "3          4  0.464  0.008\n",
       "4          5  1.365  0.214\n",
       "5          6  0.449  0.021\n",
       "6          8  0.596  0.028\n",
       "7          9  1.085  0.051\n",
       "8         10  0.370  0.018\n",
       "9         11  0.368  0.029\n",
       "10        12  0.360  0.013\n",
       "11        13  0.512  0.030\n",
       "12        17  2.309  0.629\n",
       "13        19  5.328  0.000\n",
       "14        22  0.363  0.032\n",
       "15        28  3.181  2.766\n",
       "16        29  0.564  0.001\n",
       "17        32  0.361  0.025\n",
       "18        33  0.381  0.014\n",
       "19        34  4.826  0.140\n",
       "20        35  0.412  0.029\n",
       "21        36  0.382  0.014\n",
       "22        38  1.074  0.535\n",
       "23        39  0.397  0.021\n",
       "24        40  1.176  0.603\n",
       "25        42  0.390  0.020\n",
       "26        44  1.257  0.111\n",
       "27        45  2.718  0.298\n",
       "28        52  0.426  0.043\n",
       "29        53  0.384  0.016\n",
       "30        54  0.398  0.043\n",
       "31        55  0.405  0.023\n",
       "32        56  0.551  0.106\n",
       "33        61  0.386  0.020\n",
       "34        62  0.417  0.054\n",
       "35        63  0.399  0.044\n",
       "36        65  0.456  0.064\n",
       "37        66  0.368  0.009\n",
       "38        70  0.353  0.006\n",
       "39        71  0.399  0.044\n",
       "40        72  0.382  0.027\n",
       "41        73  0.386  0.015\n",
       "42        75  0.404  0.020\n",
       "43        77  0.348  0.004\n",
       "44        80  0.534  0.018\n",
       "45        81  0.398  0.018\n",
       "46        82  0.386  0.024\n",
       "47        83  0.394  0.016\n",
       "48        90  0.350  0.020"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read results\n",
    "results = pd.read_csv('caco/tdc_test_set_results.txt', sep=',', header=None, dtype={0: int, 1: float, 2: float})\n",
    "# set columns\n",
    "results.columns = ['trial_id', 'mean', 'std']\n",
    "results\n",
    "# order res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c418a24aeebde864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T14:36:15.112525941Z",
     "start_time": "2023-11-21T14:36:15.098272445Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_id</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>77</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>90</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>70</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>66</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>72</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>73</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>61</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>82</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>42</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>83</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>81</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>54</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>71</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>75</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>55</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>62</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>52</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>65</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>80</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>56</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38</td>\n",
       "      <td>1.074</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>1.085</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>44</td>\n",
       "      <td>1.257</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.365</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>45</td>\n",
       "      <td>2.718</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28</td>\n",
       "      <td>3.181</td>\n",
       "      <td>2.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34</td>\n",
       "      <td>4.826</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>5.328</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial_id   mean    std\n",
       "43        77  0.348  0.004\n",
       "48        90  0.350  0.020\n",
       "38        70  0.353  0.006\n",
       "10        12  0.360  0.013\n",
       "17        32  0.361  0.025\n",
       "14        22  0.363  0.032\n",
       "37        66  0.368  0.009\n",
       "9         11  0.368  0.029\n",
       "8         10  0.370  0.018\n",
       "18        33  0.381  0.014\n",
       "21        36  0.382  0.014\n",
       "40        72  0.382  0.027\n",
       "29        53  0.384  0.016\n",
       "41        73  0.386  0.015\n",
       "33        61  0.386  0.020\n",
       "46        82  0.386  0.024\n",
       "25        42  0.390  0.020\n",
       "47        83  0.394  0.016\n",
       "23        39  0.397  0.021\n",
       "45        81  0.398  0.018\n",
       "30        54  0.398  0.043\n",
       "35        63  0.399  0.044\n",
       "39        71  0.399  0.044\n",
       "42        75  0.404  0.020\n",
       "31        55  0.405  0.023\n",
       "20        35  0.412  0.029\n",
       "34        62  0.417  0.054\n",
       "28        52  0.426  0.043\n",
       "5          6  0.449  0.021\n",
       "36        65  0.456  0.064\n",
       "0          0  0.458  0.004\n",
       "3          4  0.464  0.008\n",
       "11        13  0.512  0.030\n",
       "44        80  0.534  0.018\n",
       "32        56  0.551  0.106\n",
       "16        29  0.564  0.001\n",
       "1          1  0.572  0.031\n",
       "6          8  0.596  0.028\n",
       "2          2  0.618  0.062\n",
       "22        38  1.074  0.535\n",
       "7          9  1.085  0.051\n",
       "24        40  1.176  0.603\n",
       "26        44  1.257  0.111\n",
       "4          5  1.365  0.214\n",
       "12        17  2.309  0.629\n",
       "27        45  2.718  0.298\n",
       "15        28  3.181  2.766\n",
       "19        34  4.826  0.140\n",
       "13        19  5.328  0.000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order results by mean (std in case of tie)\n",
    "results = results.sort_values(by=['mean', 'std'], ascending=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e40046d6b150ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T21:06:35.148450911Z",
     "start_time": "2023-11-11T21:06:34.234850305Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:06:34] Initializing Normalizer\n",
      "2023-11-11 21:06:34.588336: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-11-11 21:06:34.588369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: JOAOPC\n",
      "2023-11-11 21:06:34.588387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: JOAOPC\n",
      "2023-11-11 21:06:34.588490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.147.5\n",
      "2023-11-11 21:06:34.588511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.147.5\n",
      "2023-11-11 21:06:34.588516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.147.5\n"
     ]
    }
   ],
   "source": [
    "# load best trial pipeline (rank #10)\n",
    "best_trial_id = int(results.iloc[0]['trial_id'])\n",
    "pipeline = Pipeline.load(f\"caco/trial_{best_trial_id}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca45806698765d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T21:06:37.318346098Z",
     "start_time": "2023-11-11T21:06:37.310182035Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardizer',\n",
       "  <deepmol.base.transformer.PassThroughTransformer at 0x7f5a71cebfa0>),\n",
       " ('padder', <deepmol.base.transformer.DatasetTransformer at 0x7f590dbe3b20>),\n",
       " ('model', <deepmol.models.deepchem_models.DeepChemModel at 0x7f59dabe15d0>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15a26546936ad8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
